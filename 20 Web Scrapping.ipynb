{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e747380-90d1-46a1-af69-58ca6765db48",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3477436f-b85b-4a17-bcf0-dab8d7cb3f6e",
   "metadata": {},
   "source": [
    "**Web Scraping** is the process of extracting data from websites using automated methods. It involves using software tools and scripts to extract data from web pages and store it in a structured format like a spreadsheet or a database. Web Scraping is used for various purposes, such as:\n",
    "\n",
    "1. Data Mining: Web Scraping is widely used to extract data from various websites to gather insights and intelligence for businesses. This can be used to analyze market trends, competitor activity, customer behavior, and other relevant information.\n",
    "\n",
    "2. Research: Web Scraping is used by researchers to collect data on various topics from different websites. This can be used to study consumer behavior, social trends, and other relevant areas.\n",
    "\n",
    "3. Content Aggregation: Web Scraping is used to collect content from various sources and aggregate it into a single location. This can be used for news sites, job listings, and other types of content aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fb386-a961-4387-91fe-8e6e7928aa53",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79794da8-36d1-4e1e-b6c6-3a0512f11cd8",
   "metadata": {},
   "source": [
    "There are various methods used for web scraping. Some of the popular ones include:\n",
    "\n",
    "1. Manual Scraping: This involves manually copying and pasting data from web pages into a spreadsheet or database.\n",
    "\n",
    "2. DOM Parsing: This involves using the Document Object Model (DOM) to extract data from web pages. This method is useful when the data is in a structured format.\n",
    "\n",
    "3. Regular Expression Matching: This involves using regular expressions to match patterns in the HTML code of a web page and extract relevant data.\n",
    "\n",
    "4. Web Scraping Tools: There are various web scraping tools available that can automate the process of data extraction from web pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d43427-ac25-49b6-bad5-3e0c2f0d27c6",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf37cb96-5ca6-4fc0-9e47-09bcfcafbffd",
   "metadata": {},
   "source": [
    "**Beautiful Soup** is a Python library that is used to parse HTML and XML documents. It provides a simple way to navigate, search, and modify the parse tree. Beautiful Soup can be used to extract data from HTML pages and transform them into structured data.\n",
    "\n",
    "Beautiful Soup is used for web scraping because it provides an easy way to navigate through HTML and XML documents. It can be used to extract data from specific tags and attributes in HTML pages, and it can also be used to handle errors and exceptions that may occur during the parsing process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4acab1-5802-413e-9a70-e1ec7092f866",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19b53d-bf3b-4af0-82c2-17244202dbf1",
   "metadata": {},
   "source": [
    "**Flask** is a lightweight Python web framework that is used to develop web applications. Flask provides a simple and easy-to-use API that can be used to build web applications. It is also easy to set up and can be used to create a web application quickly. Flask is ideal for this Web Scraping project because it allows the scraped data to be displayed in a user-friendly manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c609c78-57c8-4dea-a6fb-1350c8373b58",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b4bd4-7572-4b46-860f-36ede268781b",
   "metadata": {},
   "source": [
    "The two AWS services used in this project are Elastic Beanstalk and CodePipeline.\n",
    "\n",
    "1. **Elastic Beanstalk:** Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web applications and services. In this project, Elastic Beanstalk was used to deploy the web application.\n",
    "\n",
    "2. **CodePipeline:** CodePipeline is a fully managed continuous delivery service that automates the build, test, and deployment of your application. In this project, CodePipeline was used to set up a pipeline that automatically builds and deploys the application to Elastic Beanstalk whenever changes are pushed to the source code repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
