{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b724379b-c02c-479d-ab5f-72f3fea79752",
   "metadata": {},
   "source": [
    "# Regression-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c033d095-d53f-45ca-b929-0a9f127a3b00",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "\n",
    "Simple linear regression is a statistical method used to model the linear relationship between a dependent variable and a single independent variable. Multiple linear regression, on the other hand, involves modeling the linear relationship between a dependent variable and multiple independent variables.\n",
    "\n",
    "1. Example of simple linear regression: Suppose you want to predict a person's weight based on their height. You collect the height and weight data of 50 people and plot it on a scatter plot. You can then fit a straight line through the data points to model the relationship between weight and height.\n",
    "\n",
    "2. Example of multiple linear regression: Suppose you want to predict a person's salary based on their age, education level, and work experience. You collect data on these variables for 100 individuals and use multiple linear regression to model the relationship between salary and the three independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0dee1-5820-446b-a339-60150c0ad39f",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "\n",
    "1. Linearity: The relationship between the dependent variable and independent variable(s) is linear.\n",
    "2. Independence: The observations are independent of each other.\n",
    "3. Homoscedasticity: The variance of the error term is constant across all levels of the independent variable(s).\n",
    "4. Normality: The error terms are normally distributed with a mean of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276698d2-cc6b-44b3-8a6b-5f04bc13a8fa",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "\n",
    "In a linear regression model, the slope represents the change in the dependent variable for a one-unit increase in the independent variable, holding all other variables constant. The intercept represents the expected value of the dependent variable when all independent variables are zero.\n",
    "\n",
    "- Example: Suppose you fit a linear regression model to predict the price of a house based on its size. The slope of the model is 100, which means that for every additional square foot of living space, the price of the house increases by \\\\$ 100'. The intercept is 50,000, which means that the expected price of a house with zero square feet of living space (i.e., a non-existent house) is  \\\\$ 50,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca8a499-4381-4950-8d06-75b9fe80a3db",
   "metadata": {},
   "source": [
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models. It works by iteratively adjusting the weights or coefficients in the model to find the values that produce the lowest cost. At each iteration, the algorithm calculates the gradient of the cost function with respect to the weights, which gives the direction of steepest descent. The weights are then updated in the opposite direction of the gradient, with a learning rate determining the size of the step. The process is repeated until the cost function reaches a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21b1a29-6b5d-4b3b-9a61-5649e78538be",
   "metadata": {},
   "source": [
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "Multiple linear regression is a statistical method used to model the linear relationship between a dependent variable and multiple independent variables. Unlike simple linear regression, which has only one independent variable, multiple linear regression can account for the effects of several variables on the dependent variable, multiple regression incorporates multiple independent variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bedcbf-ec72-417d-83e2-ff55d9a9f996",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "Multicollinearity occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. This can cause problems in the model, such as making it difficult to determine the effect of each variable on the dependent variable.\n",
    "\n",
    "To detect multicollinearity, you can calculate the correlation matrix of the independent variables and look for high correlations between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abccbc6d-782c-4168-84c0-d29e6a129c77",
   "metadata": {},
   "source": [
    "### Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "Polynomial regression is a type of regression analysis that models the relationship between the dependent variable and one or more independent variables as an nth degree polynomial. It is a form of nonlinear regression, as the relationship between the variables is not a straight line.\n",
    "\n",
    "Polynomial regression is different from linear regression in that linear regression models the relationship between the dependent variable and independent variable(s) as a straight line, whereas polynomial regression models the relationship as a curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba11ffd2-777e-4539-b0ed-446629c7e2cc",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "- Advantages of polynomial regression:\n",
    "\n",
    "1. It can capture nonlinear relationships between the independent and dependent variables.\n",
    "2. It can fit a wider range of data patterns than linear regression.\n",
    "3. It can provide a better fit for data that exhibits curvature or other nonlinear patterns.\n",
    "- Disadvantages of polynomial regression:\n",
    "\n",
    "1. It can be more complex and computationally intensive than linear regression.\n",
    "2. It may be prone to overfitting if the degree of the polynomial is too high.\n",
    "3. It can be more difficult to interpret the coefficients of a polynomial regression equation.\n",
    "\n",
    "\n",
    "In general, polynomial regression is preferred over linear regression when the relationship between the independent and dependent variables is nonlinear, and when there is reason to believe that a polynomial function is a good fit for the data. This might be the case when the data exhibits curvature or other nonlinear patterns, or when prior knowledge or theory suggests that a polynomial relationship is likely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
