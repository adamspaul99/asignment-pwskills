{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c172e49d-1d71-4aef-8a4a-b9a5e8c3f799",
   "metadata": {},
   "source": [
    "# Logistic Regression-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738ebe7-6025-46b0-a98d-596532590cef",
   "metadata": {},
   "source": [
    "### Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n",
    "Grid search cv (cross-validation) is a technique used in machine learning to tune hyperparameters of a model to obtain optimal performance. It works by creating a grid of all possible hyperparameter combinations and evaluating the model with each combination using cross-validation. The combination that produces the best performance is chosen as the optimal hyperparameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3a808-6603-432a-8ed0-77b98175aa48",
   "metadata": {},
   "source": [
    "### Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose one over the other?\n",
    "Grid search cv exhaustively searches all hyperparameter combinations in a predefined range, while random search cv randomly samples hyperparameters from a predefined distribution. Grid search cv is preferred when the number of hyperparameters is small and their effects are well understood, while random search cv is preferred when the number of hyperparameters is large or their effects are unclear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f00dde9-8164-4882-8b85-dd739d090122",
   "metadata": {},
   "source": [
    "### Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n",
    "Data leakage occurs when information from the test set is inadvertently used to train a machine learning model, leading to overfitting and unrealistically high performance on the test set. An example of data leakage is using information from the test set to preprocess the training data, such as imputing missing values or scaling the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aed049-7e1b-48be-9c73-fad296153892",
   "metadata": {},
   "source": [
    "### Q4. How can you prevent data leakage when building a machine learning model?\n",
    "Data leakage can be prevented by properly separating the training, validation, and test sets and only using information from the training set to preprocess the data. Feature scaling and imputation should be done separately for each set, and the same preprocessing steps should not be applied to both the training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc200a-f289-4b27-bbbd-bd6566a13a1b",
   "metadata": {},
   "source": [
    "### Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "A confusion matrix is a table that summarizes the performance of a classification model by showing the number of true positives, true negatives, false positives, and false negatives. It provides a detailed view of how well the model is performing and helps to identify the types of errors it is making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5098404-9e8c-4453-aa82-181eb9b0ab82",
   "metadata": {},
   "source": [
    "### Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "Q6. Precision measures the proportion of predicted positives that are true positives, while recall measures the proportion of true positives that are correctly predicted by the model. In other words, precision is the ability of the model to avoid false positives, while recall is the ability of the model to detect all true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d543665-a843-47bd-bd88-a03541610121",
   "metadata": {},
   "source": [
    "### Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "The confusion matrix can be used to identify which types of errors the model is making by examining the false positives and false negatives. False positives are cases where the model predicts a positive outcome but the true outcome is negative, while false negatives are cases where the model predicts a negative outcome but the true outcome is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b41de4-72a9-4adf-bf45-3b52ed80e4dc",
   "metadata": {},
   "source": [
    "### Q8. What are some common metrics that can be derived from a confusion matrix, and how are they calculated?\n",
    "Some common metrics that can be derived from a confusion matrix include accuracy, precision, recall, F1 score, and AUC-ROC score. Accuracy is the proportion of correct predictions, precision is the proportion of true positives among predicted positives, recall is the proportion of true positives among actual positives, F1 score is the harmonic mean of precision and recall, and AUC-ROC score measures the area under the receiver operating characteristic curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2d4d22-0310-4ed3-9ecd-00b62ff0ab89",
   "metadata": {},
   "source": [
    "### Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "The accuracy of a model is calculated as the proportion of correct predictions out of all predictions, and is represented in the confusion matrix as the sum of the true positives and true negatives divided by the total number of cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ca071-70a7-4a7a-ad87-ea9516e90a99",
   "metadata": {},
   "source": [
    "### Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning model?\n",
    "A confusion matrix can be used to identify potential biases or limitations in a machine learning model by examining the distribution of errors across different classes or features. For example, if the model consistently performs poorly on a particular class, it may indicate that the class is underrepresented or that the model is not capturing important features related to that class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
