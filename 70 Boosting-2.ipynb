{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b898dba-ceda-4604-9d63-7be866ade942",
   "metadata": {},
   "source": [
    "# Boosting-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7d0bc-7476-4341-8f7e-3fc688e796a0",
   "metadata": {},
   "source": [
    "### Q1. What is Gradient Boosting Regression?\n",
    "\n",
    "Gradient Boosting Regression is a variant of gradient boosting that is specifically designed for regression problems. It is a powerful machine learning technique that combines weak regression models (typically decision trees) to create a strong regression model. It works by iteratively fitting new models to the residuals (the differences between the actual and predicted values) of the previous models and then combining the predictions of all models to make the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9fc734-01be-4b06-9b28-f3cb13d8062b",
   "metadata": {},
   "source": [
    "### Q2. Implement a simple gradient boosting algorithm from scratch using Python and NumPy. Use a simple regression problem as an example and train the model on a small dataset. Evaluate the model's performance using metrics such as mean squared error and R-squared.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fe055e-fea5-43f2-a878-d47b812d012f",
   "metadata": {},
   "source": [
    "### Q3. Experiment with different hyperparameters such as learning rate, number of trees, and tree depth to optimise the performance of the model. Use grid search or random search to find the best hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ed1e1-61e2-464c-880c-0e55422fb504",
   "metadata": {},
   "source": [
    "### Q4. What is a weak learner in Gradient Boosting?\n",
    "\n",
    " In Gradient Boosting, a weak learner refers to a simple, relatively low-performing model that is used as a building block within the ensemble. Typically, a decision tree with limited depth is used as a weak learner in gradient boosting, although other types of models can also be used. Weak learners are called \"weak\" because they have limited predictive power on their own and tend to have high bias and low variance. However, when combined in an ensemble using gradient boosting, these weak learners can collectively create a strong and highly accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0697b47-f56e-483d-8615-78939515b14c",
   "metadata": {},
   "source": [
    "### Q5. What is the intuition behind the Gradient Boosting algorithm?\n",
    "\n",
    "The intuition behind the Gradient Boosting algorithm is to sequentially build an ensemble of models, where each subsequent model focuses on learning and correcting the mistakes made by the previous models. The algorithm starts with an initial model, usually a simple one, and then iteratively adds new models to the ensemble, each one aimed at reducing the errors of the previous models. By combining the predictions of all models, the final model becomes a strong learner capable of capturing complex relationships and making accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61cbaf0-6145-4f7a-8996-fc67305ea53a",
   "metadata": {},
   "source": [
    "### Q6. How does Gradient Boosting algorithm build an ensemble of weak learners?\n",
    "\n",
    "The Gradient Boosting algorithm builds an ensemble of weak learners by sequentially fitting them to the residuals (differences between the actual and predicted values) of the previous models. Each weak learner is trained to predict the residuals of the ensemble, meaning it aims to correct the errors made by the previous models. The predictions of all weak learners are then combined, typically by weighted averaging, to make the final prediction. The weights assigned to the weak learners reflect their contribution to the ensemble, with higher weights given to more accurate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e2a5b-7e69-4500-bc14-d08aaf1ee712",
   "metadata": {},
   "source": [
    "### Q7. What are the steps involved in constructing the mathematical intuition of Gradient Boosting algorithm?\n",
    "The steps involved in constructing the mathematical intuition of the Gradient Boosting algorithm are as follows:\n",
    "\n",
    "1. Initialize the model: Start with an initial model that predicts the mean or a constant value of the target variable.\n",
    "\n",
    "2. Calculate residuals: Calculate the differences between the actual target values and the predictions of the current model. These residuals represent the errors or discrepancies between the model's predictions and the true values.\n",
    "\n",
    "3. Fit a weak learner to residuals: Train a weak learner, such as a decision tree, on the residuals. The weak learner is fitted to the residuals to capture and learn from the errors made by the current model.\n",
    "\n",
    "4. Update the model: Add the weak learner to the ensemble by combining it with the previous models. The predictions of the weak learner are multiplied by a small learning rate (a hyperparameter) and added to the predictions of the current model. This update aims to reduce the residuals and improve the overall model's predictions.\n",
    "\n",
    "5. Repeat steps 2-4: Iterate the process by recalculating the residuals based on the updated predictions and fitting new weak learners to the residuals. Each subsequent weak learner focuses on correcting the errors made by the ensemble of previous models.\n",
    "\n",
    "6. Combine the weak learners: Finally, combine the predictions of all weak learners, usually through weighted averaging, to obtain the final prediction of the ensemble model.\n",
    "\n",
    "By sequentially training weak learners on the residuals and combining their predictions, the Gradient Boosting algorithm gradually improves the accuracy of the ensemble model, effectively reducing the overall error and making more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe7301-d08a-4070-b5e7-3d3138500237",
   "metadata": {},
   "source": [
    "## i have not completed question 2 and 3 because in hindi batch of data science and machine learning krish sir not covered python implementation of boosting techniques that why i have not given answers of 2 and 3 questions , kindly give me marks for rest of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3bfe6-5490-469d-a64c-37e7be2f6f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
