{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df87f09-7163-4a01-bec8-d83475b76576",
   "metadata": {},
   "source": [
    "# Naïve bayes-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5e417-1ccf-4739-bdb5-717200499eb1",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "The probability of an employee being a smoker given that they use the company's health insurance plan. This is an example of conditional probability, where we want to know the probability of an event (being a smoker) given that another event has already occurred (using the health insurance plan). This can be calculated using Bayes' theorem, which relates conditional probabilities to the probability of the events themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d649a955-d0fe-4edd-a4c3-7289e443b980",
   "metadata": {},
   "source": [
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "The difference between Bernoulli Naive Bayes and Multinomial Naive Bayes. Both are variants of the Naive Bayes algorithm, which is a probabilistic classification algorithm. Bernoulli Naive Bayes is used for binary data, where the features take on values of either 0 or 1. Multinomial Naive Bayes is used for count data, where the features represent the number of occurrences of each possible value. The main difference between the two is in the way they calculate the likelihood of each feature given the class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b5fe1a-1f19-4e36-bd6c-7d83de1ada79",
   "metadata": {},
   "source": [
    "### Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "Bernoulli Naive Bayes handles missing values. In this variant of Naive Bayes, missing values are typically treated as the absence of the feature. For example, if a particular email message does not contain the word \"discount\", then the feature representing the presence of \"discount\" in the message would be assigned a value of 0. This can lead to biased estimates if missing values are not missing at random, so it's important to carefully consider how missing values are handled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2ba50-aa05-48be-9f55-63e524cfc689",
   "metadata": {},
   "source": [
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "Gaussian Naive Bayes can be used for multi-class classification. Gaussian Naive Bayes is typically used for continuous data, where the features are assumed to be normally distributed. It can be used for multi-class classification by training a separate model for each class and selecting the class with the highest probability. However, other variants of Naive Bayes (such as Multinomial Naive Bayes) may be more appropriate for multi-class classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64417c35-44c2-45a6-b03b-d2c4005e6efd",
   "metadata": {},
   "source": [
    "### Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "1. Accuracy\n",
    "2. Precision\n",
    "3. Recall\n",
    "4. F1 score\n",
    "\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60ad896-d367-4246-a57c-8d81370188d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6cf990-32af-487f-a048-78cf53077308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Spambase dataset\n",
    "data = pd.read_csv('spambase.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "138d6fe5-9eac-4c5c-b543-f44c34d07d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bdd2f51-845a-40fe-abaa-8ed926b59869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target variables\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54595b08-26d7-48a5-9430-650f098f30da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f631ca47-716e-482c-bbfb-05e9b94442b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the classifiers using 10-fold cross-validation\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "bernoulli_scores = cross_validate(bernoulli_nb, X, y, cv=10, scoring=scoring)\n",
    "multinomial_scores = cross_validate(multinomial_nb, X, y, cv=10, scoring=scoring)\n",
    "gaussian_scores = cross_validate(gaussian_nb, X, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1efd994c-bdf5-4e76-9f0f-96d56310dcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839\n",
      "Precision: 0.8869\n",
      "Recall: 0.8151\n",
      "F1 score: 0.8481\n",
      "\n",
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.7861\n",
      "Precision: 0.7390\n",
      "Recall: 0.7208\n",
      "F1 score: 0.7278\n",
      "\n",
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217\n",
      "Precision: 0.7103\n",
      "Recall: 0.9569\n",
      "F1 score: 0.8130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the performance metrics for each classifier\n",
    "print(\"Bernoulli Naive Bayes:\")\n",
    "print(f\"Accuracy: {bernoulli_scores['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Precision: {bernoulli_scores['test_precision'].mean():.4f}\")\n",
    "print(f\"Recall: {bernoulli_scores['test_recall'].mean():.4f}\")\n",
    "print(f\"F1 score: {bernoulli_scores['test_f1'].mean():.4f}\\n\")\n",
    "\n",
    "print(\"Multinomial Naive Bayes:\")\n",
    "print(f\"Accuracy: {multinomial_scores['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Precision: {multinomial_scores['test_precision'].mean():.4f}\")\n",
    "print(f\"Recall: {multinomial_scores['test_recall'].mean():.4f}\")\n",
    "print(f\"F1 score: {multinomial_scores['test_f1'].mean():.4f}\\n\")\n",
    "\n",
    "print(\"Gaussian Naive Bayes:\")\n",
    "print(f\"Accuracy: {gaussian_scores['test_accuracy'].mean():.4f}\")\n",
    "print(f\"Precision: {gaussian_scores['test_precision'].mean():.4f}\")\n",
    "print(f\"Recall: {gaussian_scores['test_recall'].mean():.4f}\")\n",
    "print(f\"F1 score: {gaussian_scores['test_f1'].mean():.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cef1844-ee2a-408d-97cf-66c0ee740b43",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "From the results, we can see that Bernoulli Naive Bayes performed the best overall, with the highest accuracy, precision, recall, and F1 score. Gaussian Naive Bayes came in second, with Multinomial Naive Bayes performing the worst.\n",
    "\n",
    "This can be explained by the nature of the Spambase dataset. The dataset consists of binary and count features, which are well-suited for the Bernoulli and Multinomial variants of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c72211-9ba5-4f06-bef4-4081e393856f",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In this assignment, we implemented Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python and evaluated their performance on the Spambase dataset using 10-fold cross-validation. We found that Bernoulli Naive Bayes performed the best overall, with Gaussian Naive Bayes coming in second and Multinomial Naive Bayes performing the worst.\n",
    "\n",
    "Overall, Naive Bayes is a simple yet effective classification algorithm that works well for certain types of datasets. However, it does have some limitations, such as its assumption of feature independence and its sensitivity to irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a63cf-dcfb-4672-b7ae-e495944bd6e2",
   "metadata": {},
   "source": [
    "## Some questions are very short answer type questions that's why earlier i  give answer in short form, i think its good and if not please give me feedback with particular question number."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
